{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing gait detection\n",
    "This script preprocesses the sensor data, tabulates it into windows, and generates features. \n",
    "\n",
    "Execution time $\\approx$ 50s per participant (amounting to 35 minutes in total)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdathome.constants import global_constants as gc\n",
    "# from pdathome.preprocessing import preprocess_gait_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hbv002...\n",
      "Processing hbv012...\n",
      "Processing hbv014...\n",
      "Processing hbv015...\n",
      "Processing hbv016...\n",
      "Processing hbv017...\n",
      "Processing hbv022...\n",
      "Processing hbv024...\n",
      "Processing hbv039...\n",
      "Processing hbv043...\n",
      "Processing hbv047...\n",
      "Processing hbv054...\n",
      "Processing hbv065...\n",
      "Processing hbv077...\n",
      "Processing hbv079...\n",
      "Processing hbv090...\n",
      "Processing hbv013...\n",
      "Processing hbv018...\n",
      "Processing hbv023...\n",
      "Processing hbv038...\n",
      "Processing hbv058...\n",
      "Processing hbv063...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from paradigma.preprocessing_config import IMUPreprocessingConfig\n",
    "from paradigma.gait.gait_analysis_config import GaitFeatureExtractionConfig\n",
    "from paradigma.gait.feature_extraction import extract_temporal_domain_features, extract_spectral_domain_features\n",
    "from paradigma.imu_preprocessing import butterworth_filter\n",
    "from paradigma.segmenting import tabulate_windows\n",
    "\n",
    "def compute_mode(data):\n",
    "    \"\"\"Computes the mode for 1D data using np.unique.\"\"\"\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    max_count_index = np.argmax(counts)\n",
    "    return values[max_count_index], counts[max_count_index]\n",
    "\n",
    "def is_majority(data, target=\"Walking\"):\n",
    "    \"\"\"Checks if 'target' occurs more than half the time in 1D data.\"\"\"\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    target_count = counts[values == target].sum() if target in values else 0\n",
    "    return target_count > (len(data) / 2)\n",
    "\n",
    "for subject in gc.participant_ids.L_PD_IDS:\n",
    "    print(f'Processing {subject}...')\n",
    "    for side in [gc.descriptives.MOST_AFFECTED_SIDE, gc.descriptives.LEAST_AFFECTED_SIDE]:\n",
    "        df = pd.read_pickle(os.path.join(gc.paths.PATH_PREPARED_DATA, f'{subject}_{side}.pkl'))\n",
    "\n",
    "        config = IMUPreprocessingConfig()\n",
    "        config.acceleration_units = 'g'\n",
    "\n",
    "        # Extract relevant gc.columns for accelerometer data\n",
    "        accel_cols = ['accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "\n",
    "        # Change to correct units [g]\n",
    "        df[accel_cols] = df[accel_cols] / 9.81 if config.acceleration_units == 'm/s^2' else df[accel_cols]\n",
    "\n",
    "        # Extract accelerometer data\n",
    "        accel_data = df[accel_cols].values\n",
    "\n",
    "        filter_configs = {\n",
    "            \"hp\": {\"result_columns\": accel_cols, \"replace_original\": True},\n",
    "            \"lp\": {\"result_columns\": [f'{col}_grav' for col in accel_cols], \"replace_original\": False},\n",
    "        }\n",
    "\n",
    "        # Apply filters in a loop\n",
    "        for passband, filter_config in filter_configs.items():\n",
    "            filtered_data = butterworth_filter(\n",
    "                data=accel_data,\n",
    "                order=config.filter_order,\n",
    "                cutoff_frequency=config.lower_cutoff_frequency,\n",
    "                passband=passband,\n",
    "                sampling_frequency=config.sampling_frequency,\n",
    "            )\n",
    "\n",
    "            # Replace or add new columns based on configuration\n",
    "            df[filter_config[\"result_columns\"]] = filtered_data\n",
    "\n",
    "        config = GaitFeatureExtractionConfig()\n",
    "\n",
    "        windowed_data = []\n",
    "\n",
    "        l_windowed_cols = [\n",
    "            gc.columns.TIME, gc.columns.FREE_LIVING_LABEL\n",
    "            ] + config.l_accelerometer_cols + config.l_gravity_cols\n",
    "        \n",
    "        if subject in gc.participant_ids.L_PD_IDS:\n",
    "            l_windowed_cols += [gc.columns.ARM_LABEL]\n",
    "\n",
    "        if subject in gc.participant_ids.L_PD_IDS:\n",
    "            df_grouped = df.groupby(gc.columns.PRE_OR_POST, sort=False)\n",
    "            order = ['pre', 'post']\n",
    "\n",
    "            for label in order:\n",
    "                if label in df_grouped.groups:  # Ensure the label exists in the groups\n",
    "                    group = df_grouped.get_group(label)\n",
    "                    windows = tabulate_windows(\n",
    "                        config=config,\n",
    "                        df=group,\n",
    "                        columns=l_windowed_cols\n",
    "                    )\n",
    "                    if len(windows) > 0:  # Skip if no windows are created\n",
    "                        windowed_data.append(windows)\n",
    "\n",
    "        else:\n",
    "            windows = tabulate_windows(\n",
    "                config=config,\n",
    "                df=df,\n",
    "                columns=l_windowed_cols\n",
    "            )\n",
    "            if len(windows) > 0:  # Skip if no windows are created\n",
    "                windowed_data.append(windows)\n",
    "\n",
    "        if len(windowed_data) > 0:\n",
    "            windowed_data = np.concatenate(windowed_data, axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"No windows were created from the given data.\")\n",
    "        \n",
    "        df_features = pd.DataFrame()\n",
    "\n",
    "        df_features[gc.columns.TIME] = sorted(windowed_data[:, 0, l_windowed_cols.index(gc.columns.TIME)])\n",
    "\n",
    "        if subject in gc.participant_ids.L_PD_IDS:\n",
    "            df_features = pd.merge(left=df_features, right=df[[gc.columns.TIME, gc.columns.PRE_OR_POST]], how='left', on=gc.columns.TIME) \n",
    "\n",
    "        # Calulate the mode of the labels\n",
    "        windowed_labels = windowed_data[:, :, l_windowed_cols.index(gc.columns.FREE_LIVING_LABEL)]\n",
    "        modes_and_counts = np.apply_along_axis(lambda x: compute_mode(x), axis=1, arr=windowed_labels)\n",
    "        modes, counts = zip(*modes_and_counts)\n",
    "\n",
    "        df_features[gc.columns.ACTIVITY_LABEL_MAJORITY_VOTING] = modes\n",
    "        df_features[gc.columns.GAIT_MAJORITY_VOTING] = [is_majority(window) for window in windowed_labels]\n",
    "\n",
    "        if subject in gc.participant_ids.L_PD_IDS:\n",
    "            windowed_labels = windowed_data[:, :, l_windowed_cols.index(gc.columns.ARM_LABEL)]\n",
    "            modes_and_counts = np.apply_along_axis(lambda x: compute_mode(x), axis=1, arr=windowed_labels)\n",
    "            modes, counts = zip(*modes_and_counts)\n",
    "\n",
    "            df_features[gc.columns.ARM_LABEL_MAJORITY_VOTING] = modes\n",
    "            df_features[gc.columns.NO_OTHER_ARM_ACTIVITY_MAJORITY_VOTING] = [is_majority(window, target=\"Gait without other behaviours or other positions\") for window in windowed_labels]\n",
    "\n",
    "        # compute statistics of the temporal domain signals\n",
    "        accel_indices = [l_windowed_cols.index(x) for x in config.l_accelerometer_cols]\n",
    "        grav_indices = [l_windowed_cols.index(x) for x in config.l_gravity_cols]\n",
    "\n",
    "        accel_windowed = np.asarray(windowed_data[:, :, np.min(accel_indices):np.max(accel_indices) + 1], dtype=float)\n",
    "        grav_windowed = np.asarray(windowed_data[:, :, np.min(grav_indices):np.max(grav_indices) + 1], dtype=float)\n",
    "\n",
    "        df_temporal_features = extract_temporal_domain_features(\n",
    "            config=config,\n",
    "            windowed_acc=accel_windowed,\n",
    "            windowed_grav=grav_windowed,\n",
    "            l_grav_stats=['mean', 'std']\n",
    "        )\n",
    "\n",
    "        df_features = pd.concat([df_features, df_temporal_features], axis=1)\n",
    "\n",
    "        # transform the signals from the temporal domain to the spectral domain using the fast fourier transform\n",
    "        # and extract spectral features\n",
    "        df_spectral_features = extract_spectral_domain_features(\n",
    "            config=config,\n",
    "            sensor=config.sensor,\n",
    "            windowed_data=accel_windowed,\n",
    "        )\n",
    "\n",
    "        df_features = pd.concat([df_features, df_spectral_features], axis=1)\n",
    "        \n",
    "        file_path = os.path.join(gc.paths.PATH_GAIT_FEATURES, f'{subject}_{side}.pkl')\n",
    "        df_features.to_pickle(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>0.022984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>0.045723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>0.064985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>0.081866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>0.114953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8145 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      std_norm\n",
       "0     0.029423\n",
       "1     0.006257\n",
       "2     0.005415\n",
       "3     0.003488\n",
       "4     0.002488\n",
       "...        ...\n",
       "8140  0.022984\n",
       "8141  0.045723\n",
       "8142  0.064985\n",
       "8143  0.081866\n",
       "8144  0.114953\n",
       "\n",
       "[8145 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[[x for x in df_features.columns if 'norm' in x]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd-at-home-4UNzdMX4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
