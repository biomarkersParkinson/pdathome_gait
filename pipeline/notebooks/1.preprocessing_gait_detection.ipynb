{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing gait detection\n",
    "This script preprocesses the sensor data, tabulates it into windows, and generates features. \n",
    "\n",
    "Execution time $\\approx$ 50s per participant (amounting to 35 minutes in total)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdathome.constants import global_constants as gc\n",
    "# from pdathome.preprocessing import preprocess_gait_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hbv002...\n",
      "Processing hbv012...\n",
      "Processing hbv014...\n",
      "Processing hbv015...\n",
      "Processing hbv016...\n",
      "Processing hbv017...\n",
      "Processing hbv022...\n",
      "Processing hbv024...\n",
      "Processing hbv039...\n",
      "Processing hbv043...\n",
      "Processing hbv054...\n",
      "Processing hbv065...\n",
      "Processing hbv077...\n",
      "Processing hbv079...\n",
      "Processing hbv090...\n",
      "Processing hbv013...\n",
      "Processing hbv018...\n",
      "Processing hbv023...\n",
      "Processing hbv038...\n",
      "Processing hbv058...\n",
      "Processing hbv063...\n",
      "Processing hbv053...\n",
      "Processing hbv072...\n",
      "Processing hbv073...\n",
      "Processing hbv082...\n",
      "Processing hbv083...\n",
      "Processing hbv084...\n",
      "Processing hbv087...\n",
      "Processing hbv091...\n",
      "Processing hbv093...\n",
      "Processing hbv097...\n",
      "Processing hbv099...\n",
      "Processing hbv100...\n",
      "Processing hbv106...\n",
      "Processing hbv108...\n",
      "Processing hbv109...\n",
      "Processing hbv110...\n",
      "Processing hbv112...\n",
      "Processing hbv115...\n",
      "Processing hbv117...\n",
      "Processing hbv122...\n",
      "Processing hbv128...\n",
      "Processing hbv136...\n",
      "Processing hbv081...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from paradigma.config import IMUConfig, GaitFeatureExtractionConfig\n",
    "from paradigma.gait.feature_extraction import extract_temporal_domain_features, extract_spectral_domain_features\n",
    "from paradigma.preprocessing import butterworth_filter\n",
    "from paradigma.segmenting import tabulate_windows\n",
    "\n",
    "def compute_mode(data):\n",
    "    \"\"\"Computes the mode for 1D data using np.unique.\"\"\"\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    max_count_index = np.argmax(counts)\n",
    "    return values[max_count_index], counts[max_count_index]\n",
    "\n",
    "def is_majority(data, target=\"Walking\"):\n",
    "    \"\"\"Checks if 'target' occurs more than half the time in 1D data.\"\"\"\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    target_count = counts[values == target].sum() if target in values else 0\n",
    "    return target_count > (len(data) / 2)\n",
    "\n",
    "for subject in gc.participant_ids.PD_IDS + gc.participant_ids.HC_IDS:\n",
    "    print(f'Processing {subject}...')\n",
    "    for side in [gc.descriptives.MOST_AFFECTED_SIDE, gc.descriptives.LEAST_AFFECTED_SIDE]:\n",
    "        df = pd.read_parquet(os.path.join(gc.paths.PATH_PREPARED_DATA, f'{subject}_{side}.parquet'))\n",
    "\n",
    "        config = IMUConfig()\n",
    "        config.acceleration_units = 'g'\n",
    "\n",
    "        # Change to correct units [g]\n",
    "        df[gc.columns.ACCELEROMETER_COLS] = df[gc.columns.ACCELEROMETER_COLS] / 9.81 if config.acceleration_units == 'm/s^2' else df[gc.columns.ACCELEROMETER_COLS]\n",
    "\n",
    "        # Extract accelerometer data\n",
    "        accel_data = df[gc.columns.ACCELEROMETER_COLS].values\n",
    "\n",
    "        filter_configs = {\n",
    "            \"hp\": {\"result_columns\": gc.columns.ACCELEROMETER_COLS, \"replace_original\": True},\n",
    "            \"lp\": {\"result_columns\": [f'{col}_grav' for col in gc.columns.ACCELEROMETER_COLS], \"replace_original\": False},\n",
    "        }\n",
    "\n",
    "        # Apply filters in a loop\n",
    "        for passband, filter_config in filter_configs.items():\n",
    "            filtered_data = butterworth_filter(\n",
    "                data=accel_data,\n",
    "                order=config.filter_order,\n",
    "                cutoff_frequency=config.lower_cutoff_frequency,\n",
    "                passband=passband,\n",
    "                sampling_frequency=config.sampling_frequency,\n",
    "            )\n",
    "\n",
    "            # Replace or add new columns based on configuration\n",
    "            df[filter_config[\"result_columns\"]] = filtered_data\n",
    "\n",
    "        config = GaitFeatureExtractionConfig()\n",
    "\n",
    "        windowed_data = []\n",
    "\n",
    "        l_windowed_cols = [\n",
    "            gc.columns.TIME, gc.columns.FREE_LIVING_LABEL\n",
    "            ] + config.accelerometer_cols + config.gravity_cols\n",
    "        \n",
    "        if subject in gc.participant_ids.PD_IDS:\n",
    "            l_windowed_cols += [gc.columns.ARM_LABEL]\n",
    "\n",
    "            df_grouped = df.groupby(gc.columns.PRE_OR_POST, sort=False)\n",
    "            order = ['pre', 'post']\n",
    "\n",
    "            for label in order:\n",
    "                if label in df_grouped.groups:  # Ensure the label exists in the groups\n",
    "                    group = df_grouped.get_group(label)\n",
    "                    windows = tabulate_windows(\n",
    "                        df=group,\n",
    "                        columns=l_windowed_cols,\n",
    "                        window_length_s=config.window_length_s,\n",
    "                        window_step_length_s=config.window_step_length_s,\n",
    "                        fs=config.sampling_frequency\n",
    "                    )\n",
    "                    if len(windows) > 0:  # Skip if no windows are created\n",
    "                        windowed_data.append(windows)\n",
    "\n",
    "        else:\n",
    "            windows = tabulate_windows(\n",
    "                df=df,\n",
    "                columns=l_windowed_cols,\n",
    "                window_length_s=config.window_length_s,\n",
    "                window_step_length_s=config.window_step_length_s,\n",
    "                fs=config.sampling_frequency\n",
    "            )\n",
    "            if len(windows) > 0:  # Skip if no windows are created\n",
    "                windowed_data.append(windows)\n",
    "\n",
    "        if len(windowed_data) > 0:\n",
    "            windowed_data = np.concatenate(windowed_data, axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"No windows were created from the given data.\")\n",
    "        \n",
    "        df_features = pd.DataFrame()\n",
    "\n",
    "        df_features[gc.columns.TIME] = sorted(windowed_data[:, 0, l_windowed_cols.index(gc.columns.TIME)])\n",
    "\n",
    "        if subject in gc.participant_ids.PD_IDS:\n",
    "            df_features = pd.merge(left=df_features, right=df[[gc.columns.TIME, gc.columns.PRE_OR_POST]], how='left', on=gc.columns.TIME) \n",
    "\n",
    "        # Calulate the mode of the labels\n",
    "        windowed_labels = windowed_data[:, :, l_windowed_cols.index(gc.columns.FREE_LIVING_LABEL)]\n",
    "        modes_and_counts = np.apply_along_axis(lambda x: compute_mode(x), axis=1, arr=windowed_labels)\n",
    "        modes, counts = zip(*modes_and_counts)\n",
    "\n",
    "        df_features[gc.columns.ACTIVITY_LABEL_MAJORITY_VOTING] = modes\n",
    "        df_features[gc.columns.GAIT_MAJORITY_VOTING] = [is_majority(window) for window in windowed_labels]\n",
    "\n",
    "        if subject in gc.participant_ids.PD_IDS:\n",
    "            windowed_labels = windowed_data[:, :, l_windowed_cols.index(gc.columns.ARM_LABEL)]\n",
    "            modes_and_counts = np.apply_along_axis(lambda x: compute_mode(x), axis=1, arr=windowed_labels)\n",
    "            modes, counts = zip(*modes_and_counts)\n",
    "\n",
    "            df_features[gc.columns.ARM_LABEL_MAJORITY_VOTING] = modes\n",
    "            df_features[gc.columns.NO_OTHER_ARM_ACTIVITY_MAJORITY_VOTING] = [is_majority(window, target=\"Gait without other behaviours or other positions\") for window in windowed_labels]\n",
    "\n",
    "        # compute statistics of the temporal domain signals\n",
    "        accel_indices = [l_windowed_cols.index(x) for x in config.accelerometer_cols]\n",
    "        grav_indices = [l_windowed_cols.index(x) for x in config.gravity_cols]\n",
    "\n",
    "        accel_windowed = np.asarray(windowed_data[:, :, np.min(accel_indices):np.max(accel_indices) + 1], dtype=float)\n",
    "        grav_windowed = np.asarray(windowed_data[:, :, np.min(grav_indices):np.max(grav_indices) + 1], dtype=float)\n",
    "\n",
    "        df_temporal_features = extract_temporal_domain_features(\n",
    "            config=config,\n",
    "            windowed_acc=accel_windowed,\n",
    "            windowed_grav=grav_windowed,\n",
    "            grav_stats=['mean', 'std']\n",
    "        )\n",
    "\n",
    "        df_features = pd.concat([df_features, df_temporal_features], axis=1)\n",
    "\n",
    "        # transform the signals from the temporal domain to the spectral domain using the fast fourier transform\n",
    "        # and extract spectral features\n",
    "        df_spectral_features = extract_spectral_domain_features(\n",
    "            config=config,\n",
    "            sensor=config.sensor,\n",
    "            windowed_data=accel_windowed,\n",
    "        )\n",
    "\n",
    "        df_features = pd.concat([df_features, df_spectral_features], axis=1)\n",
    "        \n",
    "        file_path = os.path.join(gc.paths.PATH_GAIT_FEATURES, f'{subject}_{side}.parquet')\n",
    "        df_features.to_parquet(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pd-at-home-4UNzdMX4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
