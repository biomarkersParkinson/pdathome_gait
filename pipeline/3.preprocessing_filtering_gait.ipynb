{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# # if you are unable to load pdathome.constants, you need to add the path to the src folder to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pdathome.constants import *\n",
    "from pdathome.preprocessing import arm_label_majority_voting\n",
    "\n",
    "from paradigma.constants import DataColumns\n",
    "from paradigma.feature_extraction import pca_transform_gyroscope, compute_angle, remove_moving_average_angle, \\\n",
    "    signal_to_ffts, extract_angle_extremes, extract_range_of_motion, extract_peak_angular_velocity, \\\n",
    "    get_dominant_frequency, compute_perc_power, extract_temporal_domain_features, extract_spectral_domain_features\n",
    "from paradigma.gait_analysis_config import ArmSwingFeatureExtractionConfig\n",
    "from paradigma.imu_preprocessing import butterworth_filter\n",
    "from paradigma.preprocessing_config import IMUPreprocessingConfig\n",
    "from paradigma.windowing import tabulate_windows, create_segments, discard_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_config = IMUPreprocessingConfig()\n",
    "arm_activity_config = ArmSwingFeatureExtractionConfig()\n",
    "\n",
    "imu_config.acceleration_units = 'g'\n",
    "\n",
    "arm_activity_config.pred_gait_proba_colname = 'pred_gait_proba'\n",
    "arm_activity_config.pred_gait_colname = 'pred_gait'\n",
    "arm_activity_config.l_data_point_level_cols += [arm_activity_config.time_colname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ids = ['hbv002', 'hbv012', 'hbv053']\n",
    "\n",
    "l_data_point_level_cols = ([arm_activity_config.time_colname, 'pre_or_post', 'gait_boolean',\n",
    "                            arm_activity_config.angle_colname, arm_activity_config.velocity_colname] + \\\n",
    "                            arm_activity_config.l_gyroscope_cols + arm_activity_config.l_accelerometer_cols + \\\n",
    "                            [x+'_grav' for x in arm_activity_config.l_accelerometer_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_THRESHOLDS, 'gait_thresholds.txt'), 'r') as f:\n",
    "    threshold = float(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 2024-09-18 11:13:41.574145 - hbv002 MAS - Processing ...\n",
      "Time 2024-09-18 11:13:56.223487 - hbv002 LAS - Processing ...\n"
     ]
    }
   ],
   "source": [
    "for subject in ['hbv002']: #l_ids:     \n",
    "    # Load gait predictions   \n",
    "    df_pred = pd.read_pickle(os.path.join(PATH_GAIT_PREDICTIONS, f'{subject}_ts.pkl'))\n",
    "\n",
    "    # Load clinical distribution of participants\n",
    "    with open(os.path.join(PATH_CLINICAL_DATA, 'distribution_participants.json'), 'r') as f:\n",
    "        d_participant_distribution = json.load(f)\n",
    "\n",
    "    # Configure columns based on cohort\n",
    "    if subject in L_PD_IDS:\n",
    "        file_sensor_data = 'phys_cur_PD_merged.mat'\n",
    "        path_annotations = PATH_ANNOTATIONS_PD\n",
    "        l_cols_to_export = [arm_activity_config.time_colname, arm_activity_config.segment_nr_colname, 'window_nr', 'arm_label', 'pre_or_post']\n",
    "    else:\n",
    "        file_sensor_data = 'phys_cur_HC_merged.mat'\n",
    "        path_annotations = PATH_ANNOTATIONS_CONTROLS\n",
    "        l_cols_to_export = [arm_activity_config.time_colname, arm_activity_config.segment_nr_colname, 'window_nr']\n",
    "\n",
    "    l_dfs = []\n",
    "\n",
    "    for side in [MOST_AFFECTED_SIDE, LEAST_AFFECTED_SIDE]:\n",
    "        print(f\"Time {datetime.datetime.now()} - {subject} {side} - Processing ...\")\n",
    "\n",
    "        # Load sensor data\n",
    "        df_sensors = pd.read_pickle(os.path.join(PATH_DATAFRAMES, f'{subject}_{side}.pkl'))\n",
    "        df_pred_side = df_pred.loc[df_pred['side']==side].copy()\n",
    "\n",
    "        for col in imu_config.d_channels_accelerometer.keys():\n",
    "            # Change to correct units [g]\n",
    "            if imu_config.acceleration_units == 'm/s^2':\n",
    "                df_sensors[col] /= 9.81\n",
    "\n",
    "            for result, side_pass in zip(['filt', 'grav'], ['hp', 'lp']):\n",
    "                df_sensors[f'{result}_{col}'] = butterworth_filter(\n",
    "                    single_sensor_col=np.array(df_sensors[col]),\n",
    "                    order=imu_config.filter_order,\n",
    "                    cutoff_frequency=imu_config.lower_cutoff_frequency,\n",
    "                    passband=side_pass,\n",
    "                    sampling_frequency=imu_config.sampling_frequency,\n",
    "                )\n",
    "                    \n",
    "            df_sensors = df_sensors.drop(columns=[col]).rename(columns={f'filt_{col}': col})\n",
    "\n",
    "\n",
    "        # Merge sensor data with predictions\n",
    "        l_merge_cols = [arm_activity_config.time_colname, 'free_living_label']\n",
    "        if subject in L_PD_IDS:\n",
    "            l_merge_cols += ['pre_or_post', 'arm_label']\n",
    "\n",
    "        df = pd.merge(left=df_pred_side, right=df_sensors, how='left', on=l_merge_cols).reset_index(drop=True)\n",
    "\n",
    "        # Process free living label and remove nans\n",
    "        df['gait_boolean'] = (df['free_living_label'] == 'Walking').astype(int)\n",
    "        df = df.dropna(subset=arm_activity_config.l_gyroscope_cols)\n",
    "            \n",
    "        # Apply threshold and filter data\n",
    "        df[arm_activity_config.pred_gait_colname] = (df[arm_activity_config.pred_gait_proba_colname] >= threshold).astype(int)\n",
    "\n",
    "        df.loc[df[arm_activity_config.pred_gait_proba_colname]>=threshold, arm_activity_config.pred_gait_colname] = 1\n",
    "        df.loc[df[arm_activity_config.pred_gait_proba_colname]<threshold, arm_activity_config.pred_gait_colname] = 0\n",
    "\n",
    "        # Perform principal component analysis on the gyroscope signals to obtain the angular velocity in the\n",
    "        # direction of the swing of the arm \n",
    "        df[arm_activity_config.velocity_colname] = pca_transform_gyroscope(\n",
    "            df=df,\n",
    "            y_gyro_colname=DataColumns.GYROSCOPE_Y,\n",
    "            z_gyro_colname=DataColumns.GYROSCOPE_Z,\n",
    "            pred_gait_colname=arm_activity_config.pred_gait_colname\n",
    "        )\n",
    "\n",
    "        # Integrate the angular velocity to obtain an estimation of the angle\n",
    "        df[arm_activity_config.angle_colname] = compute_angle(\n",
    "            velocity_col=df[arm_activity_config.velocity_colname],\n",
    "            time_col=df[arm_activity_config.time_colname]\n",
    "        )\n",
    "\n",
    "        # Remove the moving average from the angle to account for possible drift caused by the integration\n",
    "        # of noise in the angular velocity\n",
    "        df[arm_activity_config.angle_smooth_colname] = remove_moving_average_angle(\n",
    "            angle_col=df[arm_activity_config.angle_colname],\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "        \n",
    "        # Filter unobserved data\n",
    "        if subject in L_PD_IDS:\n",
    "            df = df[df['arm_label'] != 'cant assess']\n",
    "        \n",
    "        # Use only predicted gait for the subsequent steps\n",
    "        df = df[df[arm_activity_config.pred_gait_colname] == 1].reset_index(drop=True)\n",
    "\n",
    "        # Group consecutive timestamps into segments with new segments starting after a pre-specified gap\n",
    "        df = create_segments(\n",
    "            df=df,\n",
    "            time_colname=arm_activity_config.time_colname,\n",
    "            segment_nr_colname=arm_activity_config.segment_nr_colname,\n",
    "            minimum_gap_s=arm_activity_config.window_length_s\n",
    "        )\n",
    "\n",
    "        # Remove any segments that do not adhere to predetermined criteria\n",
    "        df = discard_segments(\n",
    "            df=df,\n",
    "            time_colname=arm_activity_config.time_colname,\n",
    "            segment_nr_colname=arm_activity_config.segment_nr_colname,\n",
    "            minimum_segment_length_s=arm_activity_config.window_length_s\n",
    "        )\n",
    "\n",
    "        # Create windows of fixed length and step size from the time series\n",
    "        l_data_point_level_cols = arm_activity_config.l_data_point_level_cols + (['pre_or_post', 'arm_label'] if subject in L_PD_IDS else [])\n",
    "\n",
    "        l_dfs = [\n",
    "            tabulate_windows(\n",
    "                df=df[df[arm_activity_config.segment_nr_colname] == segment_nr].reset_index(drop=True),\n",
    "                time_column_name=arm_activity_config.time_colname,\n",
    "                data_point_level_cols=l_data_point_level_cols,\n",
    "                segment_nr_colname=arm_activity_config.segment_nr_colname,\n",
    "                window_length_s=arm_activity_config.window_length_s,\n",
    "                window_step_size_s=arm_activity_config.window_step_size_s,\n",
    "                segment_nr=segment_nr,\n",
    "                sampling_frequency=arm_activity_config.sampling_frequency\n",
    "            )\n",
    "            for segment_nr in df[arm_activity_config.segment_nr_colname].unique()\n",
    "        ]\n",
    "        df_windowed = pd.concat(l_dfs).reset_index(drop=True)\n",
    "\n",
    "        # Save windows with timestamps for later use\n",
    "        df_windowed[l_cols_to_export].to_pickle(os.path.join(PATH_ARM_ACTIVITY_FEATURES, f'{subject}_{side}_ts.pkl'))\n",
    "\n",
    "        df_windowed = df_windowed.drop(columns=[arm_activity_config.time_colname])\n",
    "\n",
    "        # Majority voting for labels per window\n",
    "        if subject in L_PD_IDS:\n",
    "            df_windowed['other_arm_activity_majority_voting'] = df_windowed['arm_label'].apply(lambda x: x.count('Gait without other behaviours or other positions') < len(x)/2)\n",
    "            df_windowed['arm_label_majority_voting'] = df_windowed['arm_label'].apply(lambda x: arm_label_majority_voting(arm_activity_config, x))\n",
    "            df_windowed = df_windowed.drop(columns=['arm_label'])\n",
    "    \n",
    "        # Transform the angle from the temporal domain to the spectral domain using the fast fourier transform\n",
    "        df_windowed['angle_freqs'], df_windowed['angle_fft'] = signal_to_ffts(\n",
    "            sensor_col=df_windowed[arm_activity_config.angle_smooth_colname],\n",
    "            window_type=arm_activity_config.window_type,\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "\n",
    "        # Obtain the dominant frequency of the angle signal in the frequency band of interest\n",
    "        # defined by the highest peak in the power spectrum\n",
    "        df_windowed['angle_dominant_frequency'] = df_windowed.apply(\n",
    "            lambda x: get_dominant_frequency(\n",
    "                signal_ffts=x['angle_fft'],\n",
    "                signal_freqs=x['angle_freqs'],\n",
    "                fmin=arm_activity_config.power_band_low_frequency,\n",
    "                fmax=arm_activity_config.power_band_high_frequency\n",
    "                ),\n",
    "             axis=1\n",
    "        )\n",
    "\n",
    "        df_windowed = df_windowed.drop(columns=['angle_fft', 'angle_freqs'])\n",
    "\n",
    "        # Compute the percentage of power in the frequency band of interest (i.e., the frequency band of the arm swing)\n",
    "        df_windowed['angle_perc_power'] = df_windowed[arm_activity_config.angle_smooth_colname].apply(\n",
    "            lambda x: compute_perc_power(\n",
    "                sensor_col=x,\n",
    "                fmin_band=arm_activity_config.power_band_low_frequency,\n",
    "                fmax_band=arm_activity_config.power_band_high_frequency,\n",
    "                fmin_total=arm_activity_config.spectrum_low_frequency,\n",
    "                fmax_total=arm_activity_config.spectrum_high_frequency,\n",
    "                sampling_frequency=arm_activity_config.sampling_frequency,\n",
    "                window_type=arm_activity_config.window_type\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Determine the extrema (minima and maxima) of the angle signal\n",
    "        extract_angle_extremes(\n",
    "            df=df_windowed,\n",
    "            angle_colname=arm_activity_config.angle_smooth_colname,\n",
    "            dominant_frequency_colname='angle_dominant_frequency',\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "\n",
    "        # Calculate the change in angle between consecutive extrema (minima and maxima) of the angle signal inside the window\n",
    "        df_windowed['angle_amplitudes'] = extract_range_of_motion(angle_extrema_values_col=df_windowed['angle_extrema_values'])\n",
    "\n",
    "        # Aggregate the changes in angle between consecutive extrema to obtain the range of motion\n",
    "        df_windowed['range_of_motion'] = df_windowed['angle_amplitudes'].apply(lambda x: np.mean(x) if len(x) > 0 else 0).replace(np.nan, 0)\n",
    "        df_windowed = df_windowed.drop(columns=['angle_amplitudes'])\n",
    "\n",
    "        # Compute the forward and backward peak angular velocity using the extrema of the angular velocity\n",
    "        extract_peak_angular_velocity(\n",
    "            df=df_windowed,\n",
    "            velocity_colname=arm_activity_config.velocity_colname,\n",
    "            angle_minima_colname='angle_minima',\n",
    "            angle_maxima_colname='angle_maxima'\n",
    "        )\n",
    "\n",
    "        # Compute aggregated measures of the peak angular velocity\n",
    "        for dir in ['forward', 'backward']:\n",
    "            df_windowed[f'{dir}_peak_ang_vel_mean'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n",
    "            df_windowed[f'{dir}_peak_ang_vel_std'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.std(x) if len(x) > 0 else 0)\n",
    "            df_windowed = df_windowed.drop(columns=[f'{dir}_peak_ang_vel'])\n",
    "\n",
    "        # Compute statistics of the temporal domain accelerometer signals\n",
    "        df_windowed = extract_temporal_domain_features(arm_activity_config, df_windowed, l_gravity_stats=['mean', 'std'])\n",
    "\n",
    "        # Transform the accelerometer and gyroscope signals from the temporal domain to the spectral domain\n",
    "        # using the fast fourier transform and extract spectral features\n",
    "        for sensor, l_sensor_colnames in zip(['accelerometer', 'gyroscope'], [arm_activity_config.l_accelerometer_cols, arm_activity_config.l_gyroscope_cols]):\n",
    "            df_windowed = extract_spectral_domain_features(arm_activity_config, df_windowed, sensor, l_sensor_colnames)\n",
    "        \n",
    "        df_windowed.fillna(0, inplace=True)\n",
    "        df_windowed['side'] = side\n",
    "\n",
    "        l_export_cols = [arm_activity_config.time_colname, arm_activity_config.segment_nr_colname, 'window_nr', 'other_arm_activity_majority_voting', 'arm_label_majority_voting'] + list(arm_activity_config.d_channels_values.keys())\n",
    "\n",
    "        df_windowed[l_export_cols].to_pickle(os.path.join(PATH_ARM_ACTIVITY_FEATURES, f'{subject}_{side}.pkl'))\n",
    "\n",
    "        # clear_output(wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait-3c0zjlKo-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
