{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# # if you are unable to load pdathome.constants, you need to add the path to the src folder to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pdathome.constants import columns, descriptives, participant_ids, paths\n",
    "from pdathome.preprocessing import arm_label_majority_voting\n",
    "\n",
    "from paradigma.constants import DataColumns\n",
    "from paradigma.feature_extraction import pca_transform_gyroscope, compute_angle, remove_moving_average_angle, \\\n",
    "    signal_to_ffts, extract_angle_extremes, extract_range_of_motion, extract_peak_angular_velocity, \\\n",
    "    get_dominant_frequency, compute_perc_power, extract_temporal_domain_features, extract_spectral_domain_features\n",
    "from paradigma.gait_analysis_config import ArmSwingFeatureExtractionConfig\n",
    "from paradigma.imu_preprocessing import butterworth_filter\n",
    "from paradigma.preprocessing_config import IMUPreprocessingConfig\n",
    "from paradigma.windowing import tabulate_windows, create_segments, discard_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_config = IMUPreprocessingConfig()\n",
    "arm_activity_config = ArmSwingFeatureExtractionConfig()\n",
    "\n",
    "imu_config.acceleration_units = 'g'\n",
    "\n",
    "arm_activity_config.l_data_point_level_cols += [columns.TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_data_point_level_cols = ([columns.TIME, columns.PRE_OR_POST, 'gait_boolean',\n",
    "                            columns.ANGLE, columns.VELOCITY] + \\\n",
    "                            columns.L_GYROSCOPE + columns.L_ACCELEROMETER + \\\n",
    "                            [f'grav_{x}' for x in columns.L_ACCELEROMETER])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(paths.PATH_THRESHOLDS, 'gait_thresholds.txt'), 'r') as f:\n",
    "    threshold = float(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in ['hbv002', 'hbv012']:# subject in participant_ids.L_PD_IDS + participant_ids.L_HC_IDS:     \n",
    "    # Load gait predictions   \n",
    "    df_pred = pd.read_pickle(os.path.join(paths.PATH_GAIT_PREDICTIONS, f'{subject}.pkl'))\n",
    "\n",
    "    # Load clinical distribution of participants\n",
    "    with open(os.path.join(paths.PATH_CLINICAL_DATA, 'distribution_participants.json'), 'r') as f:\n",
    "        d_participant_distribution = json.load(f)\n",
    "\n",
    "    # Configure columns based on cohort\n",
    "    if subject in participant_ids.L_PD_IDS:\n",
    "        file_sensor_data = 'phys_cur_PD_merged.mat'\n",
    "        path_annotations = paths.PATH_ANNOTATIONS_PD\n",
    "        l_cols_to_export = [\n",
    "            columns.TIME, columns.SEGMENT_NR,\n",
    "            columns.WINDOW_NR, columns.ARM_LABEL, columns.PRE_OR_POST\n",
    "        ]\n",
    "    else:\n",
    "        file_sensor_data = 'phys_cur_HC_merged.mat'\n",
    "        path_annotations = paths.PATH_ANNOTATIONS_CONTROLS\n",
    "        l_cols_to_export = [columns.TIME, columns.SEGMENT_NR, columns.WINDOW_NR]\n",
    "\n",
    "    l_dfs = []\n",
    "\n",
    "    for side in [descriptives.MOST_AFFECTED_SIDE, descriptives.LEAST_AFFECTED_SIDE]:\n",
    "        print(f\"Time {datetime.datetime.now()} - {subject} {side} - Processing ...\")\n",
    "\n",
    "        # Load sensor data\n",
    "        df_sensors = pd.read_pickle(os.path.join(paths.PATH_DATAFRAMES, f'{subject}_{side}.pkl'))\n",
    "        df_pred_side = df_pred.loc[df_pred[columns.SIDE]==side].copy()\n",
    "\n",
    "        config = IMUPreprocessingConfig()\n",
    "        config.acceleration_units = 'g'\n",
    "\n",
    "        # Extract relevant columns for accelerometer data\n",
    "        accel_cols = list(config.d_channels_accelerometer.keys())\n",
    "\n",
    "        # Change to correct units [g]\n",
    "        df_sensors[accel_cols] = df_sensors[accel_cols] / 9.81 if config.acceleration_units == 'm/s^2' else df_sensors[accel_cols]\n",
    "\n",
    "        # Extract the accelerometer data as a 2D array\n",
    "        accel_data = df_sensors[accel_cols].values\n",
    "\n",
    "        # Define filtering passbands\n",
    "        passbands = ['hp', 'lp'] \n",
    "        filtered_data = {}\n",
    "\n",
    "        # Apply Butterworth filter for each passband and result type\n",
    "        for result, passband in zip(['filt', 'grav'], passbands):\n",
    "            filtered_data[result] = butterworth_filter(\n",
    "                sensor_data=accel_data,\n",
    "                order=config.filter_order,\n",
    "                cutoff_frequency=config.lower_cutoff_frequency,\n",
    "                passband=passband,\n",
    "                sampling_frequency=config.sampling_frequency\n",
    "            )\n",
    "\n",
    "        # Create DataFrames from filtered data\n",
    "        filtered_dfs = {f'{result}_{col}': pd.Series(data[:, i]) for i, col in enumerate(accel_cols) for result, data in filtered_data.items()}\n",
    "\n",
    "        # Combine filtered columns into DataFrame\n",
    "        filtered_df = pd.DataFrame(filtered_dfs)\n",
    "\n",
    "        # Drop original accelerometer columns and append filtered results\n",
    "        df_sensors = df_sensors.drop(columns=accel_cols).join(filtered_df).rename(columns={col: col.replace('filt_', '') for col in filtered_df.columns})\n",
    "\n",
    "        # Merge sensor data with predictions\n",
    "        l_merge_cols = [columns.TIME, columns.FREE_LIVING_LABEL]\n",
    "        if subject in participant_ids.L_PD_IDS:\n",
    "            l_merge_cols += [columns.PRE_OR_POST, columns.ARM_LABEL]\n",
    "\n",
    "        df = pd.merge(left=df_pred_side, right=df_sensors, how='left', on=l_merge_cols).reset_index(drop=True)\n",
    "\n",
    "        # Process free living label and remove nans\n",
    "        df['gait_boolean'] = (df[columns.FREE_LIVING_LABEL] == 'Walking').astype(int)\n",
    "        df = df.dropna(subset=columns.L_GYROSCOPE)\n",
    "            \n",
    "        # Apply threshold and filter data\n",
    "        df[columns.PRED_GAIT] = (df[columns.PRED_GAIT_PROBA] >= threshold).astype(int)\n",
    "\n",
    "        # Perform principal component analysis on the gyroscope signals to obtain the angular velocity in the\n",
    "        # direction of the swing of the arm \n",
    "        df[columns.VELOCITY] = pca_transform_gyroscope(\n",
    "            df=df,\n",
    "            y_gyro_colname=columns.GYROSCOPE_Y,\n",
    "            z_gyro_colname=columns.GYROSCOPE_Z,\n",
    "            pred_gait_colname=columns.PRED_GAIT\n",
    "        )\n",
    "\n",
    "        # Integrate the angular velocity to obtain an estimation of the angle\n",
    "        df[columns.ANGLE] = compute_angle(\n",
    "            velocity_col=df[columns.VELOCITY],\n",
    "            time_col=df[columns.TIME]\n",
    "        )\n",
    "\n",
    "        # Remove the moving average from the angle to account for possible drift caused by the integration\n",
    "        # of noise in the angular velocity\n",
    "        df[columns.ANGLE_SMOOTH] = remove_moving_average_angle(\n",
    "            angle_col=df[columns.ANGLE],\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "        \n",
    "        # Filter unobserved data\n",
    "        if subject in participant_ids.L_PD_IDS:\n",
    "            df = df[df[columns.ARM_LABEL] != 'cant assess']\n",
    "        \n",
    "        # Use only predicted gait for the subsequent steps\n",
    "        df = df[df[columns.PRED_GAIT] == 1].reset_index(drop=True)\n",
    "\n",
    "        # Group consecutive timestamps into segments with new segments starting after a pre-specified gap\n",
    "        df = create_segments(\n",
    "            df=df,\n",
    "            time_colname=columns.TIME,\n",
    "            segment_nr_colname=columns.SEGMENT_NR,\n",
    "            minimum_gap_s=arm_activity_config.window_length_s\n",
    "        )\n",
    "\n",
    "        # Remove any segments that do not adhere to predetermined criteria\n",
    "        df = discard_segments(\n",
    "            df=df,\n",
    "            time_colname=columns.TIME,\n",
    "            segment_nr_colname=columns.SEGMENT_NR,\n",
    "            minimum_segment_length_s=arm_activity_config.window_length_s\n",
    "        )\n",
    "\n",
    "        # Create windows of fixed length and step size from the time series\n",
    "        l_data_point_level_cols = arm_activity_config.l_data_point_level_cols + ([columns.PRE_OR_POST, columns.ARM_LABEL] if subject in participant_ids.L_PD_IDS else [])\n",
    "\n",
    "        l_dfs = [\n",
    "            tabulate_windows(\n",
    "                df=df[df[columns.SEGMENT_NR] == segment_nr].reset_index(drop=True),\n",
    "                time_column_name=columns.TIME,\n",
    "                data_point_level_cols=l_data_point_level_cols,\n",
    "                segment_nr_colname=columns.SEGMENT_NR,\n",
    "                window_length_s=arm_activity_config.window_length_s,\n",
    "                window_step_size_s=arm_activity_config.window_step_size_s,\n",
    "                segment_nr=segment_nr,\n",
    "                sampling_frequency=arm_activity_config.sampling_frequency\n",
    "            )\n",
    "            for segment_nr in df[columns.SEGMENT_NR].unique()\n",
    "        ]\n",
    "        l_dfs = [df for df in l_dfs if not df.empty]\n",
    "\n",
    "        df_windowed = pd.concat(l_dfs).reset_index(drop=True)\n",
    "\n",
    "        # Save windows with timestamps for later use\n",
    "        df_windowed[l_cols_to_export].to_pickle(os.path.join(paths.PATH_ARM_ACTIVITY_FEATURES, f'{subject}_{side}_ts.pkl'))\n",
    "\n",
    "        df_windowed = df_windowed.drop(columns=[columns.TIME])\n",
    "\n",
    "        # Majority voting for labels per window\n",
    "        if subject in participant_ids.L_PD_IDS:\n",
    "            df_windowed[columns.PRE_OR_POST] = df_windowed[columns.PRE_OR_POST].str[0]\n",
    "            df_windowed[columns.OTHER_ARM_ACTIVITY_MAJORITY_VOTING] = df_windowed[columns.ARM_LABEL].apply(lambda x: x.count('Gait without other behaviours or other positions') < len(x)/2)\n",
    "            df_windowed[columns.ARM_LABEL_MAJORITY_VOTING] = df_windowed[columns.ARM_LABEL].apply(lambda x: arm_label_majority_voting(arm_activity_config, x))\n",
    "            df_windowed = df_windowed.drop(columns=[columns.ARM_LABEL])\n",
    "    \n",
    "        # Transform the angle from the temporal domain to the spectral domain using the fast fourier transform\n",
    "        df_windowed[f'{columns.ANGLE}_freqs'], df_windowed[f'{columns.ANGLE}_fft'] = signal_to_ffts(\n",
    "            sensor_col=df_windowed[columns.ANGLE_SMOOTH],\n",
    "            window_type=arm_activity_config.window_type,\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "\n",
    "        # Obtain the dominant frequency of the angle signal in the frequency band of interest\n",
    "        # defined by the highest peak in the power spectrum\n",
    "        df_windowed[f'{columns.ANGLE}_dominant_frequency'] = df_windowed.apply(\n",
    "            lambda x: get_dominant_frequency(\n",
    "                signal_ffts=x[f'{columns.ANGLE}_fft'],\n",
    "                signal_freqs=x[f'{columns.ANGLE}_freqs'],\n",
    "                fmin=arm_activity_config.power_band_low_frequency,\n",
    "                fmax=arm_activity_config.power_band_high_frequency\n",
    "                ),\n",
    "             axis=1\n",
    "        )\n",
    "\n",
    "        df_windowed = df_windowed.drop(columns=[f'{columns.ANGLE}_fft', f'{columns.ANGLE}_freqs'])\n",
    "\n",
    "        # Compute the percentage of power in the frequency band of interest (i.e., the frequency band of the arm swing)\n",
    "        df_windowed[f'{columns.ANGLE}_perc_power'] = df_windowed[columns.ANGLE_SMOOTH].apply(\n",
    "            lambda x: compute_perc_power(\n",
    "                sensor_col=x,\n",
    "                fmin_band=arm_activity_config.power_band_low_frequency,\n",
    "                fmax_band=arm_activity_config.power_band_high_frequency,\n",
    "                fmin_total=arm_activity_config.spectrum_low_frequency,\n",
    "                fmax_total=arm_activity_config.spectrum_high_frequency,\n",
    "                sampling_frequency=arm_activity_config.sampling_frequency,\n",
    "                window_type=arm_activity_config.window_type\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Determine the extrema (minima and maxima) of the angle signal\n",
    "        extract_angle_extremes(\n",
    "            df=df_windowed,\n",
    "            angle_colname=columns.ANGLE_SMOOTH,\n",
    "            dominant_frequency_colname=f'{columns.ANGLE}_dominant_frequency',\n",
    "            sampling_frequency=arm_activity_config.sampling_frequency\n",
    "        )\n",
    "\n",
    "        # Calculate the change in angle between consecutive extrema (minima and maxima) of the angle signal inside the window\n",
    "        df_windowed[f'{columns.ANGLE}_amplitudes'] = extract_range_of_motion(angle_extrema_values_col=df_windowed[f'{columns.ANGLE}_extrema_values'])\n",
    "\n",
    "        # Aggregate the changes in angle between consecutive extrema to obtain the range of motion\n",
    "        df_windowed['range_of_motion'] = df_windowed[f'{columns.ANGLE}_amplitudes'].apply(lambda x: np.mean(x) if len(x) > 0 else 0).replace(np.nan, 0)\n",
    "        df_windowed = df_windowed.drop(columns=[f'{columns.ANGLE}_amplitudes'])\n",
    "\n",
    "        # Compute the forward and backward peak angular velocity using the extrema of the angular velocity\n",
    "        extract_peak_angular_velocity(\n",
    "            df=df_windowed,\n",
    "            velocity_colname=columns.VELOCITY,\n",
    "            angle_minima_colname=f'{columns.ANGLE}_minima',\n",
    "            angle_maxima_colname=f'{columns.ANGLE}_maxima'\n",
    "        )\n",
    "\n",
    "        # Compute aggregated measures of the peak angular velocity\n",
    "        for dir in ['forward', 'backward']:\n",
    "            df_windowed[f'{dir}_peak_ang_vel_mean'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.mean(x) if len(x) > 0 else 0)\n",
    "            df_windowed[f'{dir}_peak_ang_vel_std'] = df_windowed[f'{dir}_peak_ang_vel'].apply(lambda x: np.std(x) if len(x) > 0 else 0)\n",
    "            df_windowed = df_windowed.drop(columns=[f'{dir}_peak_ang_vel'])\n",
    "\n",
    "        # Compute statistics of the temporal domain accelerometer signals\n",
    "        df_windowed = extract_temporal_domain_features(arm_activity_config, df_windowed, l_gravity_stats=['mean', 'std'])\n",
    "\n",
    "        # Transform the accelerometer and gyroscope signals from the temporal domain to the spectral domain\n",
    "        # using the fast fourier transform and extract spectral features\n",
    "        for sensor, l_sensor_colnames in zip(['accelerometer', 'gyroscope'], [columns.L_ACCELEROMETER, columns.L_GYROSCOPE]):\n",
    "            df_windowed = extract_spectral_domain_features(arm_activity_config, df_windowed, sensor, l_sensor_colnames)\n",
    "        \n",
    "        df_windowed.fillna(0, inplace=True)\n",
    "        df_windowed[columns.SIDE] = side\n",
    "\n",
    "        l_export_cols = [columns.TIME, columns.PRE_OR_POST, columns.SEGMENT_NR, columns.WINDOW_NR, columns.OTHER_ARM_ACTIVITY_MAJORITY_VOTING, columns.ARM_LABEL_MAJORITY_VOTING] + list(arm_activity_config.d_channels_values.keys())\n",
    "\n",
    "        df_windowed[l_export_cols].to_pickle(os.path.join(paths.PATH_ARM_ACTIVITY_FEATURES, f'{subject}_{side}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait-3c0zjlKo-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
